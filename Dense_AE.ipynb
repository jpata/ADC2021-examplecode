{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Layer, ReLU, LeakyReLU, Dropout\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import load_model, save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mpp-hep.github.io/ADC2021/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python3 create_datasets.py --bkg_file background_for_training.h5 --output_bkg_name bkg --signals_files Ato4l_lepFilter_13TeV.h5 --output_signal_names signal_1 --signals_files hChToTauNu_13TeV_PU20.h5 --output_signal_names signal_2 --signals_files hToTauTau_13TeV_PU20.h5 --output_signal_names signal_3 --signals_files leptoquark_LOWMASS_lepFilter_13TeV.h5 --output_signal_names signal_4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bkg_dataset.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure input data has correct input shape - background training data\n",
    "with h5py.File(filename, 'r') as file:\n",
    "    X_train = np.array(file['X_train'])\n",
    "    X_test = np.array(file['X_test'])\n",
    "    X_val = np.array(file['X_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dense NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 57\n",
    "latent_dimension = 128\n",
    "num_nodes=[32,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "inputArray = Input(shape=(input_shape))\n",
    "x = Dense(num_nodes[0], use_bias=False)(inputArray)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(latent_dimension, use_bias=False)(x)\n",
    "encoder = Activation('relu')(x)\n",
    "\n",
    "#decoder\n",
    "x = Dense(num_nodes[0], use_bias=False)(encoder)\n",
    "x = Activation('relu')(x)\n",
    "decoder = Dense(input_shape)(x)\n",
    "\n",
    "#create autoencoder\n",
    "autoencoder = Model(inputs = inputArray, outputs=decoder)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = keras.optimizers.Adam(lr=1e-2), loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 5*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(X_train, X_train, epochs = EPOCHS, batch_size = BATCH_SIZE,\n",
    "                  validation_data=(X_val, X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.ylim(0,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dense'\n",
    "model_directory = 'models/'\n",
    "save_model(model_directory+model_name, autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction - background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_prediction = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction - signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct signal labels\n",
    "signal_labels = ['signal_1','signal_2', 'signal_3', 'signal_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add correct path to signal files\n",
    "signals_file = ['signal_1_dataset.h5', 'signal_2_dataset.h5', 'signal_3_dataset.h5', 'signal_4_dataset.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read signal data\n",
    "signal_data = []\n",
    "for i, label in enumerate(signal_labels):\n",
    "    with h5py.File(signals_file[i], 'r') as file:\n",
    "        test_data = np.array(file['Data'])\n",
    "    signal_data.append(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_results = []\n",
    "\n",
    "for i, label in enumerate(signal_labels):\n",
    "    signal_prediction = autoencoder.predict(signal_data[i])\n",
    "    signal_results.append([label, signal_data[i], signal_prediction]) # save [label, true, prediction] for signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = 'predictions.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_file, 'w') as file:\n",
    "    file.create_dataset('BKG_input', data=X_test)\n",
    "    file.create_dataset('BKG_predicted', data = bkg_prediction)\n",
    "    for i, sig in enumerate(signal_results):\n",
    "        file.create_dataset('%s_input' %sig[0], data=sig[1])\n",
    "        file.create_dataset('%s_predicted' %sig[0], data=sig[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results\n",
    "\n",
    "1. Plot loss distribution after prediction (check loss value for signals)\n",
    "2. Plot ROC curves - how good is anomaly detection for chosen FPR threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute loss value (true, predicted)\n",
    "total_loss = []\n",
    "loss_labels = []\n",
    "\n",
    "total_loss.append(mse_loss(X_test, bkg_prediction.astype(np.float32)).numpy())\n",
    "loss_labels.append(\"bkg\")\n",
    "\n",
    "for i, signal_X in enumerate(signal_data):\n",
    "    total_loss.append(mse_loss(signal_X, signal_results[i][2].astype(np.float32)).numpy())\n",
    "    loss_labels.append(signal_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_size=100\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for loss, label in zip(total_loss, loss_labels):\n",
    "    plt.hist(loss, bins=np.logspace(-1,5,100), label=label, density = True, histtype='step', fill=False, linewidth=1.5)\n",
    "plt.yscale('log')\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Autoencoder Loss\")\n",
    "plt.ylabel(\"Probability (a.u.)\")\n",
    "plt.title('MSE loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([['Background'], np.array(signal_labels)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_background = np.zeros(total_loss[0].shape[0])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, label in enumerate(labels):\n",
    "    if i == 0: continue # background events\n",
    "    \n",
    "    trueVal = np.concatenate((np.ones(total_loss[i].shape[0]), target_background)) # anomaly=1, bkg=0\n",
    "    predVal_loss = np.concatenate((total_loss[i], total_loss[0]))\n",
    "\n",
    "    fpr_loss, tpr_loss, threshold_loss = roc_curve(trueVal, predVal_loss)\n",
    "\n",
    "    auc_loss = auc(fpr_loss, tpr_loss)\n",
    "    \n",
    "    plt.plot(fpr_loss, tpr_loss, \"-\", label='%s (auc = %.1f%%)'%(label,auc_loss*100.), linewidth=1.5)\n",
    "    \n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend(loc='center right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "plt.plot(np.linspace(0, 1),np.linspace(0, 1), '--', color='0.75')\n",
    "plt.axvline(0.00001, color='red', linestyle='dashed', linewidth=1) # threshold value for measuring anomaly detection efficiency\n",
    "plt.title(\"ROC AE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
